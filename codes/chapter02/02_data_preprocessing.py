#!/usr/bin/env python3
"""
Chapter 2: ë°ì´í„° ì „ì²˜ë¦¬ ë° ì •ì œ
Data preprocessing and cleaning script
"""

import pandas as pd
import numpy as np
import os
from datetime import datetime

def load_and_preprocess_data(filename):
    """Load and preprocess NVIDIA data"""
    
    script_dir = os.path.dirname(os.path.abspath(__file__))
    data_dir = os.path.join(script_dir, "..", "data")
    filepath = os.path.join(data_dir, filename)
    
    if not os.path.exists(filepath):
        print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {filepath}")
        return None
    
    print(f"ğŸ“Š ë°ì´í„° ë¡œë”©: {filename}")
    
    # Load data
    df = pd.read_csv(filepath, index_col=0, parse_dates=True)
    
    print(f"ì›ë³¸ ë°ì´í„° í¬ê¸°: {df.shape}")
    print(f"ë‚ ì§œ ë²”ìœ„: {df.index[0]} ~ {df.index[-1]}")
    
    # Check for missing values
    missing_values = df.isnull().sum()
    print(f"\nê²°ì¸¡ê°’ í™•ì¸:")
    for col, missing in missing_values.items():
        if missing > 0:
            print(f"  {col}: {missing}ê°œ ({missing/len(df)*100:.2f}%)")
        else:
            print(f"  {col}: ê²°ì¸¡ê°’ ì—†ìŒ")
    
    # Remove rows with missing values
    original_length = len(df)
    df = df.dropna()
    removed_rows = original_length - len(df)
    
    if removed_rows > 0:
        print(f"\nğŸ§¹ {removed_rows}ê°œ í–‰ ì œê±° (ê²°ì¸¡ê°’ í¬í•¨)")
    
    # Check for duplicate dates
    duplicates = df.index.duplicated().sum()
    if duplicates > 0:
        print(f"ğŸ” ì¤‘ë³µ ë‚ ì§œ ë°œê²¬: {duplicates}ê°œ")
        df = df[~df.index.duplicated(keep='first')]
        print(f"   ì¤‘ë³µ ì œê±° í›„ í¬ê¸°: {df.shape}")
    else:
        print("ğŸ” ì¤‘ë³µ ë‚ ì§œ ì—†ìŒ")
    
    # Sort by date
    df = df.sort_index()
    
    # Add technical indicators for data validation
    df['Daily_Return'] = df['Close'].pct_change()
    df['Price_Range'] = df['High'] - df['Low']
    df['Volume_MA_20'] = df['Volume'].rolling(window=20).mean()
    
    # Data quality checks
    print(f"\nğŸ“ˆ ë°ì´í„° í’ˆì§ˆ ê²€ì‚¬:")
    
    # Check for unrealistic price movements (>50% in one day)
    extreme_moves = abs(df['Daily_Return']) > 0.5
    extreme_count = extreme_moves.sum()
    print(f"  ê·¹ë‹¨ì  ê°€ê²© ë³€ë™ (>50%): {extreme_count}ê°œ")
    
    if extreme_count > 0:
        extreme_dates = df[extreme_moves].index
        for date in extreme_dates:
            return_val = df.loc[date, 'Daily_Return']
            print(f"    {date.strftime('%Y-%m-%d')}: {return_val:.2%}")
    
    # Check for zero volume days
    zero_volume = (df['Volume'] == 0).sum()
    print(f"  ê±°ë˜ëŸ‰ 0ì¸ ë‚ : {zero_volume}ê°œ")
    
    # Check price consistency (High >= Close >= Low, High >= Open >= Low)
    price_inconsistency = (
        (df['High'] < df['Close']) | 
        (df['High'] < df['Open']) | 
        (df['Low'] > df['Close']) | 
        (df['Low'] > df['Open'])
    ).sum()
    print(f"  ê°€ê²© ì¼ê´€ì„± ì˜¤ë¥˜: {price_inconsistency}ê°œ")
    
    # Basic statistics
    print(f"\nğŸ“Š ê¸°ë³¸ í†µê³„:")
    print(f"  í‰ê·  ì¢…ê°€: ${df['Close'].mean():.2f}")
    print(f"  ìµœê³ ê°€: ${df['High'].max():.2f}")
    print(f"  ìµœì €ê°€: ${df['Low'].min():.2f}")
    print(f"  í‰ê·  ê±°ë˜ëŸ‰: {df['Volume'].mean():,.0f}")
    print(f"  ì¼ì¼ ìˆ˜ìµë¥  í‘œì¤€í¸ì°¨: {df['Daily_Return'].std():.4f}")
    
    # Save preprocessed data
    processed_filename = filename.replace('.csv', '_processed.csv')
    processed_filepath = os.path.join(data_dir, processed_filename)
    df.to_csv(processed_filepath)
    
    print(f"\nâœ… ì „ì²˜ë¦¬ëœ ë°ì´í„° ì €ì¥: {processed_filename}")
    print(f"ìµœì¢… ë°ì´í„° í¬ê¸°: {df.shape}")
    
    return df

def preprocess_all_timeframes():
    """Preprocess all downloaded NVIDIA data files"""
    
    script_dir = os.path.dirname(os.path.abspath(__file__))
    data_dir = os.path.join(script_dir, "..", "data")
    
    # Find all NVIDIA CSV files
    nvda_files = [f for f in os.listdir(data_dir) 
                  if f.startswith("NVDA_") and f.endswith(".csv") and "_processed" not in f]
    
    if not nvda_files:
        print("âŒ NVDA ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print("ë¨¼ì € 01_data_download_multiple_timeframes.pyë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")
        return
    
    print("ğŸ”„ ëª¨ë“  íƒ€ì„í”„ë ˆì„ ë°ì´í„° ì „ì²˜ë¦¬ ì‹œì‘")
    print("=" * 50)
    
    processed_data = {}
    
    for filename in sorted(nvda_files):
        print(f"\nì²˜ë¦¬ ì¤‘: {filename}")
        print("-" * 30)
        
        df = load_and_preprocess_data(filename)
        if df is not None:
            timeframe = filename.replace("NVDA_", "").replace(".csv", "")
            processed_data[timeframe] = df
    
    print("\n" + "=" * 50)
    print("ğŸ‰ ëª¨ë“  ë°ì´í„° ì „ì²˜ë¦¬ ì™„ë£Œ!")
    
    # Summary comparison
    print(f"\nğŸ“‹ íƒ€ì„í”„ë ˆì„ë³„ ìš”ì•½:")
    for timeframe, df in processed_data.items():
        print(f"  {timeframe}:")
        print(f"    ê¸°ê°„: {df.index[0].strftime('%Y-%m-%d')} ~ {df.index[-1].strftime('%Y-%m-%d')}")
        print(f"    ë°ì´í„° í¬ì¸íŠ¸: {len(df):,}ê°œ")
        print(f"    í‰ê·  ì¢…ê°€: ${df['Close'].mean():.2f}")
        print(f"    ë³€ë™ì„±: {df['Daily_Return'].std():.4f}")

if __name__ == "__main__":
    preprocess_all_timeframes()