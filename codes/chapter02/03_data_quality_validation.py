#!/usr/bin/env python3
"""
Chapter 2: ë°ì´í„° í’ˆì§ˆ ê²€ì¦ ë° ì‹œê°í™”
Data quality validation and visualization script
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
import os
from datetime import datetime
import seaborn as sns

# Set Korean font for matplotlib
plt.rcParams['font.family'] = ['Nanum Gothic', 'Malgun Gothic', 'AppleGothic', 'Arial Unicode MS', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False  # ë§ˆì´ë„ˆìŠ¤ ê¸°í˜¸ ê¹¨ì§ ë°©ì§€
plt.rcParams['axes.unicode_minus'] = False

def validate_data_quality(df, timeframe_name):
    """Comprehensive data quality validation"""
    
    print(f"ğŸ” {timeframe_name} ë°ì´í„° í’ˆì§ˆ ê²€ì¦")
    print("-" * 40)
    
    validation_results = {}
    
    # 1. Completeness check
    total_days = (df.index[-1] - df.index[0]).days
    trading_days = len(df)
    completeness = trading_days / (total_days * 5/7)  # Approximate trading days
    
    print(f"ğŸ“… ì™„ì „ì„± ê²€ì‚¬:")
    print(f"  ì „ì²´ ê¸°ê°„: {total_days}ì¼")
    print(f"  ê±°ë˜ì¼ ìˆ˜: {trading_days}ì¼")
    print(f"  ì™„ì „ì„± ë¹„ìœ¨: {completeness:.2%}")
    
    validation_results['completeness'] = completeness
    
    # 2. Data consistency checks
    print(f"\nğŸ”§ ì¼ê´€ì„± ê²€ì‚¬:")
    
    # Price consistency
    high_low_consistent = (df['High'] >= df['Low']).all()
    high_close_consistent = (df['High'] >= df['Close']).all()
    high_open_consistent = (df['High'] >= df['Open']).all()
    low_close_consistent = (df['Low'] <= df['Close']).all()
    low_open_consistent = (df['Low'] <= df['Open']).all()
    
    price_consistent = all([high_low_consistent, high_close_consistent, 
                           high_open_consistent, low_close_consistent, low_open_consistent])
    
    print(f"  ê°€ê²© ì¼ê´€ì„±: {'âœ… í†µê³¼' if price_consistent else 'âŒ ì‹¤íŒ¨'}")
    
    # Volume consistency
    positive_volume = (df['Volume'] >= 0).all()
    print(f"  ê±°ë˜ëŸ‰ ì¼ê´€ì„±: {'âœ… í†µê³¼' if positive_volume else 'âŒ ì‹¤íŒ¨'}")
    
    validation_results['price_consistency'] = price_consistent
    validation_results['volume_consistency'] = positive_volume
    
    # 3. Outlier detection
    print(f"\nğŸ“Š ì´ìƒì¹˜ ê²€ì‚¬:")
    
    # Price outliers (using IQR method)
    Q1 = df['Close'].quantile(0.25)
    Q3 = df['Close'].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    
    price_outliers = ((df['Close'] < lower_bound) | (df['Close'] > upper_bound)).sum()
    print(f"  ê°€ê²© ì´ìƒì¹˜: {price_outliers}ê°œ ({price_outliers/len(df)*100:.2f}%)")
    
    # Return outliers (>3 standard deviations)
    returns = df['Close'].pct_change().dropna()
    return_std = returns.std()
    return_outliers = (abs(returns) > 3 * return_std).sum()
    print(f"  ìˆ˜ìµë¥  ì´ìƒì¹˜: {return_outliers}ê°œ ({return_outliers/len(returns)*100:.2f}%)")
    
    validation_results['price_outliers'] = price_outliers
    validation_results['return_outliers'] = return_outliers
    
    # 4. Missing data patterns
    print(f"\nğŸ•³ï¸ ê²°ì¸¡ê°’ íŒ¨í„´:")
    missing_data = df.isnull().sum()
    total_missing = missing_data.sum()
    print(f"  ì´ ê²°ì¸¡ê°’: {total_missing}ê°œ")
    
    if total_missing > 0:
        for col, missing in missing_data.items():
            if missing > 0:
                print(f"    {col}: {missing}ê°œ")
    else:
        print("  ê²°ì¸¡ê°’ ì—†ìŒ âœ…")
    
    validation_results['missing_data'] = total_missing
    
    # 5. Data distribution analysis
    print(f"\nğŸ“ˆ ë¶„í¬ ë¶„ì„:")
    print(f"  ê°€ê²© ë²”ìœ„: ${df['Close'].min():.2f} - ${df['Close'].max():.2f}")
    print(f"  ê°€ê²© ë³€í™”ìœ¨: {((df['Close'].iloc[-1] / df['Close'].iloc[0]) - 1) * 100:.2f}%")
    print(f"  í‰ê·  ì¼ì¼ ë³€ë™ì„±: {returns.std():.4f}")
    print(f"  ìµœëŒ€ ì¼ì¼ ìƒìŠ¹: {returns.max():.4f} ({returns.max()*100:.2f}%)")
    print(f"  ìµœëŒ€ ì¼ì¼ í•˜ë½: {returns.min():.4f} ({returns.min()*100:.2f}%)")
    
    validation_results['price_range'] = (df['Close'].min(), df['Close'].max())
    validation_results['total_return'] = ((df['Close'].iloc[-1] / df['Close'].iloc[0]) - 1)
    validation_results['volatility'] = returns.std()
    
    return validation_results

def create_quality_visualizations(timeframes_data):
    """Create comprehensive data quality visualizations"""
    
    print("\nğŸ¨ ë°ì´í„° í’ˆì§ˆ ì‹œê°í™” ìƒì„± ì¤‘...")
    
    # Create images directory relative to this script
    script_dir = os.path.dirname(os.path.abspath(__file__))
    images_dir = os.path.join(script_dir, "images")
    os.makedirs(images_dir, exist_ok=True)
    
    # 1. Price comparison across timeframes
    fig, axes = plt.subplots(2, 2, figsize=(15, 12))
    fig.suptitle('NVIDIA ì£¼ì‹ ë°ì´í„° í’ˆì§ˆ ë¶„ì„', fontsize=16, fontweight='bold')
    
    # Plot 1: Price trends
    ax1 = axes[0, 0]
    colors = ['blue', 'green', 'red']
    
    for i, (timeframe, df) in enumerate(timeframes_data.items()):
        # Normalize to show relative performance
        normalized_price = df['Close'] / df['Close'].iloc[0] * 100
        ax1.plot(df.index, normalized_price, label=f'{timeframe}', 
                color=colors[i % len(colors)], alpha=0.8)
    
    ax1.set_title('ì •ê·œí™”ëœ ê°€ê²© ì¶”ì´ ë¹„êµ')
    ax1.set_ylabel('ì •ê·œí™”ëœ ê°€ê²© (ì‹œì‘ì =100)')
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    
    # Plot 2: Volume comparison
    ax2 = axes[0, 1]
    
    for i, (timeframe, df) in enumerate(timeframes_data.items()):
        # Show recent volume (last 252 trading days for comparison)
        recent_data = df.tail(min(252, len(df)))
        ax2.plot(recent_data.index, recent_data['Volume'], 
                label=f'{timeframe}', color=colors[i % len(colors)], alpha=0.7)
    
    ax2.set_title('ìµœê·¼ ê±°ë˜ëŸ‰ ë¹„êµ')
    ax2.set_ylabel('ê±°ë˜ëŸ‰')
    ax2.legend()
    ax2.grid(True, alpha=0.3)
    
    # Plot 3: Return distribution
    ax3 = axes[1, 0]
    
    for i, (timeframe, df) in enumerate(timeframes_data.items()):
        returns = df['Close'].pct_change().dropna()
        ax3.hist(returns, bins=50, alpha=0.6, label=f'{timeframe}', 
                color=colors[i % len(colors)], density=True)
    
    ax3.set_title('ì¼ì¼ ìˆ˜ìµë¥  ë¶„í¬')
    ax3.set_xlabel('ì¼ì¼ ìˆ˜ìµë¥ ')
    ax3.set_ylabel('ë°€ë„')
    ax3.legend()
    ax3.grid(True, alpha=0.3)
    
    # Plot 4: Data quality summary
    ax4 = axes[1, 1]
    
    quality_metrics = []
    timeframe_names = []
    
    for timeframe, df in timeframes_data.items():
        returns = df['Close'].pct_change().dropna()
        
        # Calculate quality score (0-100)
        completeness_score = min(len(df) / 252, 1.0) * 25  # Max 25 points
        consistency_score = 25  # Assume good consistency
        outlier_score = max(0, 25 - (abs(returns) > 3 * returns.std()).sum())  # Max 25 points
        missing_score = 25 if df.isnull().sum().sum() == 0 else 0  # Max 25 points
        
        total_score = completeness_score + consistency_score + outlier_score + missing_score
        quality_metrics.append(total_score)
        timeframe_names.append(timeframe)
    
    bars = ax4.bar(timeframe_names, quality_metrics, color=colors[:len(timeframe_names)])
    ax4.set_title('ë°ì´í„° í’ˆì§ˆ ì ìˆ˜')
    ax4.set_ylabel('í’ˆì§ˆ ì ìˆ˜ (0-100)')
    ax4.set_ylim(0, 100)
    
    # Add value labels on bars
    for bar, score in zip(bars, quality_metrics):
        height = bar.get_height()
        ax4.text(bar.get_x() + bar.get_width()/2., height + 1,
                f'{score:.1f}', ha='center', va='bottom')
    
    ax4.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig(f'{images_dir}/data_quality_summary.png', dpi=300, bbox_inches='tight')
    plt.close()
    
    # 2. Individual timeframe analysis
    for timeframe, df in timeframes_data.items():
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        fig.suptitle(f'NVIDIA {timeframe} ë°ì´í„° ìƒì„¸ ë¶„ì„', fontsize=14, fontweight='bold')
        
        # Candlestick-style price chart
        ax1 = axes[0, 0]
        
        # Sample data for better visualization (every 10th point for long timeframes)
        sample_freq = max(1, len(df) // 500)
        sampled_df = df.iloc[::sample_freq]
        
        for i in range(len(sampled_df)):
            date = sampled_df.index[i]
            open_price = sampled_df['Open'].iloc[i]
            close_price = sampled_df['Close'].iloc[i]
            high_price = sampled_df['High'].iloc[i]
            low_price = sampled_df['Low'].iloc[i]
            
            color = 'green' if close_price >= open_price else 'red'
            
            # High-low line
            ax1.plot([date, date], [low_price, high_price], color='black', linewidth=0.5)
            # Open-close rectangle
            ax1.plot([date, date], [open_price, close_price], color=color, linewidth=2)
        
        ax1.set_title(f'{timeframe} ê°€ê²© ì°¨íŠ¸')
        ax1.set_ylabel('ê°€ê²© ($)')
        ax1.grid(True, alpha=0.3)
        
        # Volume chart
        ax2 = axes[0, 1]
        ax2.bar(sampled_df.index, sampled_df['Volume'], alpha=0.7, color='blue')
        ax2.set_title(f'{timeframe} ê±°ë˜ëŸ‰')
        ax2.set_ylabel('ê±°ë˜ëŸ‰')
        ax2.grid(True, alpha=0.3)
        
        # Returns distribution
        ax3 = axes[1, 0]
        returns = df['Close'].pct_change().dropna()
        ax3.hist(returns, bins=50, alpha=0.7, color='purple', edgecolor='black')
        ax3.axvline(returns.mean(), color='red', linestyle='--', label=f'í‰ê· : {returns.mean():.4f}')
        ax3.axvline(returns.mean() + returns.std(), color='orange', linestyle='--', alpha=0.7)
        ax3.axvline(returns.mean() - returns.std(), color='orange', linestyle='--', alpha=0.7)
        ax3.set_title('ì¼ì¼ ìˆ˜ìµë¥  ë¶„í¬')
        ax3.set_xlabel('ì¼ì¼ ìˆ˜ìµë¥ ')
        ax3.set_ylabel('ë¹ˆë„')
        ax3.legend()
        ax3.grid(True, alpha=0.3)
        
        # Rolling volatility
        ax4 = axes[1, 1]
        rolling_vol = returns.rolling(window=20).std()
        ax4.plot(rolling_vol.index, rolling_vol, color='red', alpha=0.8)
        ax4.set_title('20ì¼ ë¡¤ë§ ë³€ë™ì„±')
        ax4.set_ylabel('ë³€ë™ì„±')
        ax4.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig(f'{images_dir}/nvidia_{timeframe}_analysis.png', dpi=300, bbox_inches='tight')
        plt.close()
    
    print(f"âœ… ì‹œê°í™” ì™„ë£Œ! ì´ë¯¸ì§€ ì €ì¥ ìœ„ì¹˜: {images_dir}/")

def main():
    """Main data quality validation function"""
    
    script_dir = os.path.dirname(os.path.abspath(__file__))
    data_dir = os.path.join(script_dir, "..", "data")
    
    # Find processed data files
    processed_files = [f for f in os.listdir(data_dir) 
                      if f.startswith("NVDA_") and f.endswith("_processed.csv")]
    
    if not processed_files:
        print("âŒ ì „ì²˜ë¦¬ëœ ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print("ë¨¼ì € 02_data_preprocessing.pyë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")
        return
    
    print("ğŸ” NVIDIA ë°ì´í„° í’ˆì§ˆ ê²€ì¦ ì‹œì‘")
    print("=" * 50)
    
    timeframes_data = {}
    validation_summary = {}
    
    # Load and validate each timeframe
    for filename in sorted(processed_files):
        timeframe = filename.replace("NVDA_", "").replace("_processed.csv", "")
        
        filepath = os.path.join(data_dir, filename)
        df = pd.read_csv(filepath, index_col=0, parse_dates=True)
        
        timeframes_data[timeframe] = df
        validation_results = validate_data_quality(df, timeframe)
        validation_summary[timeframe] = validation_results
        
        print()
    
    # Create visualizations
    create_quality_visualizations(timeframes_data)
    
    # Final summary
    print("=" * 50)
    print("ğŸ“‹ ìµœì¢… ê²€ì¦ ìš”ì•½")
    print("=" * 50)
    
    for timeframe, results in validation_summary.items():
        print(f"\n{timeframe.upper()}:")
        print(f"  ì™„ì „ì„±: {results['completeness']:.2%}")
        print(f"  ê°€ê²© ì¼ê´€ì„±: {'âœ…' if results['price_consistency'] else 'âŒ'}")
        print(f"  ê±°ë˜ëŸ‰ ì¼ê´€ì„±: {'âœ…' if results['volume_consistency'] else 'âŒ'}")
        print(f"  ê°€ê²© ì´ìƒì¹˜: {results['price_outliers']}ê°œ")
        print(f"  ìˆ˜ìµë¥  ì´ìƒì¹˜: {results['return_outliers']}ê°œ")
        print(f"  ê²°ì¸¡ê°’: {results['missing_data']}ê°œ")
        print(f"  ì´ ìˆ˜ìµë¥ : {results['total_return']:.2%}")
        print(f"  ë³€ë™ì„±: {results['volatility']:.4f}")
    
    print(f"\nğŸ‰ ë°ì´í„° í’ˆì§ˆ ê²€ì¦ ì™„ë£Œ!")
    print(f"ğŸ“Š ìƒì„±ëœ ì‹œê°í™” íŒŒì¼:")
    
    script_dir = os.path.dirname(os.path.abspath(__file__))
    images_dir = os.path.join(script_dir, "images")
    for file in os.listdir(images_dir):
        if file.endswith('.png'):
            print(f"  ğŸ“ˆ {file}")

if __name__ == "__main__":
    main()